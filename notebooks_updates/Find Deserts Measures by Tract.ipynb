{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from functools import cache\n",
    "from scipy.spatial import KDTree\n",
    "from haversine import haversine\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c8542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referenced:\n",
    "# https://towardsdatascience.com/finding-time-dependent-travel-times-between-every-pair-of-locations-in-manhattan-c3c48b0db7ba\n",
    "# https://towardsdatascience.com/shortest-path-algorithm-with-osm-walking-network-6d2863ae96be\n",
    "# https://osmnx.readthedocs.io/en/stable/osmnx.html and https://github.com/gboeing/osmnx\n",
    "# https://movement.uber.com/?lang=en-US"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51307795",
   "metadata": {},
   "source": [
    "# Set City and File Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################### SET VARS HERE ###########################################################\n",
    "\n",
    "#Keep one line of the code below uncommented to find desert measures for the city of interest\n",
    "\n",
    "place = 'Cincinnati, Ohio'\n",
    "#place = 'Atlanta, Georgia'\n",
    "#place = 'Seattle, Washington'\n",
    "#place = 'Houston, Texas'\n",
    "#place = 'San Francisco, California'\n",
    "#place = 'New York, New York'\n",
    "\n",
    "# place_abbr is used to name files saved by this notebook. The commented code below shows the place_abbr strings used\n",
    "# to name files in the /data folder\n",
    "\n",
    "place_abbr = 'cinci'\n",
    "#place_abbr = 'seattle'\n",
    "#place_abbr = 'nyc'\n",
    "#place_abbr = 'houston'\n",
    "#place_abbr = 'sf'\n",
    "#place_abbr = 'atlanta'\n",
    "\n",
    "#set file path for city tract centers \n",
    "tracts_path = 'data/tract_centers/tractcenters_cinci.csv'\n",
    "\n",
    "# set file path for Uber Movement Data\n",
    "# if speed file is not available for city of interest, input path to any other speed file \n",
    "speed_path = 'data/2020_speeds_cincinnati.csv' # download this file from Uber Movement yourself\n",
    "\n",
    "# set name and directory of output file\n",
    "savename = 'data/tract_desert_measures/' + place_abbr + '_desert_tracts.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e0f212",
   "metadata": {},
   "source": [
    "# Find Desert Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d14e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tractcenters = pd.read_csv(tracts_path)\n",
    "lats = tractcenters['INTPTLAT'].to_numpy(copy=True)\n",
    "lons = tractcenters['INTPTLONG'].to_numpy(copy=True)\n",
    "tracts = tractcenters['GEOID'].to_numpy(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the graph and the speeds associated with all edges\n",
    "graph = ox.graph_from_place(place, network_type='drive')\n",
    "print('Got graph')\n",
    "graph = ox.add_edge_speeds(graph)\n",
    "print('Got speeds')\n",
    "graph = ox.add_edge_travel_times(graph)\n",
    "print('Got travel times')\n",
    "graph = ox.utils_graph.get_largest_component(graph, strongly=True)\n",
    "print('Got largest connected component')\n",
    "#ox.save_graphml(graph, r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\new_york_metro_area_cleaned.graphml')\n",
    "#graph = ox.load_graphml(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\new_york_metro_area_cleaned.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all food stores\n",
    "food_tags = {'shop': 'supermarket', 'amenity': 'marketplace'}\n",
    "food_places = ox.geometries_from_place(place, food_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Polygons with a single point\n",
    "food_places.loc[food_places['geometry'].type == 'Polygon', 'geometry'] = food_places.loc[food_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all major green places or recreational areas\n",
    "physical_tags = {'leisure': ['park', 'recreation_ground', 'playground', 'fitness_station', 'sports_centre', 'nature_reserve', 'pitch']}\n",
    "physical_places = ox.geometries_from_place(place, physical_tags)\n",
    "physical_places.loc[physical_places['geometry'].type == 'Polygon', 'geometry'] = physical_places.loc[physical_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find public transit\n",
    "transport_tags = {'public_transport': ['platform', 'stop_position'], 'highway': ['bus_stop', 'platform'],\n",
    "                 'railway': ['subway_entrance', 'station', 'tram', 'tram_stop'], 'station': 'subway'}\n",
    "transport_places = ox.geometries_from_place(place, transport_tags)\n",
    "transport_places.loc[transport_places['geometry'].type == 'Polygon', 'geometry'] = transport_places.loc[transport_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find libraries and schools\n",
    "education_tags = {'amenity': ['library', 'school', 'kindergarten']}\n",
    "education_places = ox.geometries_from_place(place, education_tags)\n",
    "education_places.loc[education_places['geometry'].type == 'Polygon', 'geometry'] = education_places.loc[education_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find places of worship\n",
    "worship_tags = {'amenity': 'place_of_worship'}\n",
    "worship_places = ox.geometries_from_place(place, worship_tags)\n",
    "worship_places.loc[worship_places['geometry'].type == 'Polygon', 'geometry'] = worship_places.loc[worship_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify everything\n",
    "food_places = food_places['geometry'].droplevel(0)\n",
    "physical_places = physical_places['geometry'].droplevel(0)\n",
    "transport_places = transport_places['geometry'].droplevel(0)\n",
    "education_places = education_places['geometry'].droplevel(0)\n",
    "worship_places = worship_places['geometry'].droplevel(0)\n",
    "food_places = food_places[food_places.type == 'Point']\n",
    "physical_places = physical_places[physical_places.type == 'Point']\n",
    "transport_places = transport_places[transport_places.type == 'Point']\n",
    "education_places = education_places[education_places.type == 'Point']\n",
    "worship_places = worship_places[worship_places.type == 'Point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_raw = pd.read_csv(speed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "speed_raw.drop(columns=['quarter', 'year', 'segment_id', 'start_junction_id', 'end_junction_id'], inplace=True)\n",
    "# Noon seems like a fair time\n",
    "speed_raw = speed_raw[speed_raw['hour_of_day'] == 12]\n",
    "speed_raw.set_index('osm_way_id', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_calculation = 0\n",
    "for edge in tqdm(graph.edges):\n",
    "   # length is meters, speed_kph is kph (duh), maxspeed has units in string, and travel_time is seconds\n",
    "    e = graph[edge[0]][edge[1]][edge[2]]\n",
    "    if isinstance(e['osmid'], list):\n",
    "       # Some graph edges are made up of multiple OSM ways apparently\n",
    "       for osmid in e['osmid']:\n",
    "            try:\n",
    "                meters_per_second = speed_raw.at[osmid, 'speed_mph_mean']*0.44704    # Convert to meters/sec\n",
    "                time = e['length']/meters_per_second\n",
    "                real_calculation += 1\n",
    "                break\n",
    "            except (KeyError, ZeroDivisionError):\n",
    "                time = e['travel_time']     # Backup (i.e. length/speed limit) if Uber data isn't available\n",
    "    else:\n",
    "        try:\n",
    "            meters_per_second = speed_raw.at[e['osmid'], 'speed_mph_mean']*0.44704\n",
    "            time = e['length']/meters_per_second\n",
    "            real_calculation += 1\n",
    "        except (KeyError, ZeroDivisionError):\n",
    "            time = e['travel_time']\n",
    "    if isinstance(time, pd.Series):\n",
    "       # TODO Bug check why this is happening, but not late at night\n",
    "        time = time.mean()\n",
    "    graph[edge[0]][edge[1]][edge[2]]['actual_travel_time'] = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nearest_nodes, dists = ox.distance.nearest_nodes(graph, lons, lats, return_dist=True)\n",
    "all_nearest_nodes = np.asarray(all_nearest_nodes)\n",
    "print('Number:', all_nearest_nodes.shape[0])\n",
    "food_closest_travel_times = np.full(all_nearest_nodes.shape[0], np.nan, dtype=np.float32)\n",
    "physical_closest_dist = food_closest_travel_times.copy()\n",
    "transport_closest_dist = food_closest_travel_times.copy()\n",
    "education_closest_travel_times = food_closest_travel_times.copy()\n",
    "worship_closest_travel_times = food_closest_travel_times.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in food_places], [x.y for x in food_places], return_dist=True)\n",
    "food_nodes = np.asarray(food_nodes)\n",
    "physical_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in physical_places], [x.y for x in physical_places], return_dist=True)\n",
    "physical_nodes = np.asarray(physical_nodes)\n",
    "transport_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in transport_places], [x.y for x in transport_places], return_dist=True)\n",
    "transport_nodes = np.asarray(transport_nodes)\n",
    "education_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in education_places], [x.y for x in education_places], return_dist=True)\n",
    "education_nodes = np.asarray(education_nodes)\n",
    "worship_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in worship_places], [x.y for x in worship_places], return_dist=True)\n",
    "worship_nodes = np.asarray(worship_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_lat_lons = np.array([[graph.nodes[x]['x'] for x in food_nodes], [graph.nodes[x]['y'] for x in food_nodes]], dtype=np.float32).T\n",
    "physical_lat_lons = np.array([[graph.nodes[x]['x'] for x in physical_nodes], [graph.nodes[x]['y'] for x in physical_nodes]], dtype=np.float32).T\n",
    "transport_lat_lons = np.array([[graph.nodes[x]['x'] for x in transport_nodes], [graph.nodes[x]['y'] for x in transport_nodes]], dtype=np.float32).T\n",
    "education_lat_lons = np.array([[graph.nodes[x]['x'] for x in education_nodes], [graph.nodes[x]['y'] for x in education_nodes]], dtype=np.float32).T\n",
    "worship_lat_lons = np.array([[graph.nodes[x]['x'] for x in worship_nodes], [graph.nodes[x]['y'] for x in worship_nodes]], dtype=np.float32).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_tree = KDTree(food_lat_lons)\n",
    "physical_tree = KDTree(physical_lat_lons)\n",
    "transport_tree = KDTree(transport_lat_lons)\n",
    "education_tree = KDTree(education_lat_lons)\n",
    "worship_tree = KDTree(worship_lat_lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_wrapper(lat1, lon1, lat2, lon2):\n",
    "    return haversine((lat1, lon1), (lat2, lon2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_food_nodes = []\n",
    "closest_education_nodes = []\n",
    "closest_worship_nodes = []\n",
    "for i, sample_node in tqdm(enumerate(all_nearest_nodes), total=len(all_nearest_nodes)):\n",
    "    idxes = food_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=5)[1]\n",
    "    closest_food_nodes.append(food_nodes[idxes])\n",
    "    idx = physical_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=1)[1]\n",
    "    dist = haversine_wrapper(graph.nodes[sample_node]['y'], graph.nodes[sample_node]['x'], physical_lat_lons[idx, 1], physical_lat_lons[idx, 0])\n",
    "    physical_closest_dist[i] = dist\n",
    "    idx = transport_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=1)[1]\n",
    "    dist = haversine_wrapper(graph.nodes[sample_node]['y'], graph.nodes[sample_node]['x'], transport_lat_lons[idx, 1], transport_lat_lons[idx, 0])\n",
    "    transport_closest_dist[i] = dist\n",
    "    idxes = education_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=5)[1]\n",
    "    closest_education_nodes.append(education_nodes[idxes])\n",
    "    idxes = worship_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=5)[1]\n",
    "    closest_worship_nodes.append(worship_nodes[idxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache    # Trying to speed things up a little\n",
    "def shortest_path(source, target):\n",
    "    return nx.shortest_path_length(graph, source=source, target=target, weight='actual_travel_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample_node in enumerate(tqdm(all_nearest_nodes)):\n",
    "    current_shortest = np.inf\n",
    "    shortest_node = 0\n",
    "    for food_node in closest_food_nodes[i]:\n",
    "        shortest = shortest_path(sample_node, food_node)\n",
    "        if shortest < current_shortest:\n",
    "            current_shortest = shortest\n",
    "            shortest_node = food_node\n",
    "    food_closest_travel_times[i] = current_shortest\n",
    "    \n",
    "    current_shortest = np.inf\n",
    "    shortest_node = 0\n",
    "    for education_node in closest_education_nodes[i]:\n",
    "        shortest = shortest_path(sample_node, education_node)\n",
    "        if shortest < current_shortest:\n",
    "            current_shortest = shortest\n",
    "            shortest_node = education_node\n",
    "    education_closest_travel_times[i] = current_shortest\n",
    "    \n",
    "    current_shortest = np.inf\n",
    "    shortest_node = 0\n",
    "    for worship_node in closest_worship_nodes[i]:\n",
    "        shortest = shortest_path(sample_node, worship_node)\n",
    "        if shortest < current_shortest:\n",
    "            current_shortest = shortest\n",
    "            shortest_node = worship_node\n",
    "    worship_closest_travel_times[i] = current_shortest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "deserts_wtracts = np.vstack((food_closest_travel_times, physical_closest_dist, transport_closest_dist, education_closest_travel_times,\n",
    "                worship_closest_travel_times)).T\n",
    "columns = ['food_closest_travel_times', 'physical_closest_dist','transport_closest_dist', \n",
    "           'education_closest_travel_times', 'worship_closest_travel_times']\n",
    "desert_measures = pd.DataFrame(deserts_wtracts, columns=columns)\n",
    "if place == 'San Francisco, California':\n",
    "    tracts = tracts.tolist()\n",
    "    tracts = ['0'+str(x) for x in tracts]\n",
    "    desert_measures['GEOID'] = tracts\n",
    "else:\n",
    "    tracts = tracts.tolist()\n",
    "    tracts = [str(x) for x in tracts]\n",
    "    desert_measures['GEOID'] = tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8806db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "desert_measures.to_csv(savename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaea763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ox]",
   "language": "python",
   "name": "conda-env-ox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
